# This patch taken from https://github.com/NixOS/nixpkgs/pull/451188/
From 987e5a27497173b8d6fa5a11efa7fa4b57b849c3 Mon Sep 17 00:00:00 2001
From: Luna Nova <git@lunnova.dev>
Date: Sat, 11 Oct 2025 15:31:57 -0700
Subject: [PATCH 1/4] rocmPackages.hipblaslt: add zstd to nativeBuildInputs

without this zstd compression of msgpack .dats silently failed
---
 pkgs/development/rocm-modules/6/hipblaslt/default.nix | 1 +
 1 file changed, 1 insertion(+)

diff --git a/pkgs/development/rocm-modules/6/hipblaslt/default.nix b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
index 8e68e0f9e62355..61328d5cd86714 100644
--- a/pkgs/development/rocm-modules/6/hipblaslt/default.nix
+++ b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
@@ -136,6 +136,7 @@ stdenv.mkDerivation (finalAttrs: {
     pkg-config
     ninja
     rocm-smi
+    zstd
   ];
 
   buildInputs = [

From 7baf5a984d40618abc1a53de6c678d2ba8cd7bbe Mon Sep 17 00:00:00 2001
From: Luna Nova <git@lunnova.dev>
Date: Sat, 11 Oct 2025 15:32:42 -0700
Subject: [PATCH 2/4] rocmPackages.hipblaslt: verify .dat files aren't huge in
 preInstallCheck

let's avoid regressing compression in future, oops
---
 .../rocm-modules/6/hipblaslt/default.nix           | 14 +++++++++++++-
 1 file changed, 13 insertions(+), 1 deletion(-)

diff --git a/pkgs/development/rocm-modules/6/hipblaslt/default.nix b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
index 61328d5cd86714..e8061a50b92f72 100644
--- a/pkgs/development/rocm-modules/6/hipblaslt/default.nix
+++ b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
@@ -125,7 +125,7 @@ stdenv.mkDerivation (finalAttrs: {
   '';
 
   doCheck = false;
-  doInstallCheck = false;
+  doInstallCheck = true;
 
   nativeBuildInputs = [
     cmake
@@ -213,6 +213,18 @@ stdenv.mkDerivation (finalAttrs: {
       rmdir $out/bin
     '';
 
+  installCheckPhase =
+    # Verify compression worked and .dat files aren't huge
+    ''
+      runHook preInstallCheck
+      find "$out" -type f -name "*.dat" -size "+2M" -exec sh -c '
+          echo "ERROR: oversized .dat file, check for issues with install compression: {}" >&2
+          exit 1
+      ' {} \;
+      echo "Verified .dat files in $out are not huge"
+      runHook postInstallCheck
+    '';
+
   # If this is false there are no kernels in the output lib
   # supporting the target device
   # so if it's an optional dep it's best to not depend on it

From 9b8dde88a3a68e61b6a302d0890eab44a8279839 Mon Sep 17 00:00:00 2001
From: Luna Nova <git@lunnova.dev>
Date: Sat, 11 Oct 2025 09:44:19 -0700
Subject: [PATCH 3/4] rocmPackages.hipblaslt: apply PR to massively reduce peak
 disk space usage

Peak build dir usage is now 25GB

# [hipblaslt] Refactor Parallel.py to drop joblib, massively reduce peak disk space usage
# https://github.com/ROCm/rocm-libraries/pull/2073
---
 .../TensileCreateLibrary-refactor.patch       | 676 ++++++++++++++++++
 .../rocm-modules/6/hipblaslt/default.nix      |   5 +-
 2 files changed, 679 insertions(+), 2 deletions(-)
 create mode 100644 pkgs/development/rocm-modules/6/hipblaslt/TensileCreateLibrary-refactor.patch

diff --git a/pkgs/development/rocm-modules/6/hipblaslt/TensileCreateLibrary-refactor.patch b/pkgs/development/rocm-modules/6/hipblaslt/TensileCreateLibrary-refactor.patch
new file mode 100644
index 00000000000000..2440b741e0045d
--- /dev/null
+++ b/pkgs/development/rocm-modules/6/hipblaslt/TensileCreateLibrary-refactor.patch
@@ -0,0 +1,676 @@
+Backport of in progress PR https://github.com/ROCm/rocm-libraries/pull/2073
+diff --git a/tensilelite/Tensile/Common/Parallel.py b/tensilelite/Tensile/Common/Parallel.py
+index 1a2bf9e119..876fe15781 100644
+--- a/tensilelite/Tensile/Common/Parallel.py
++++ b/tensilelite/Tensile/Common/Parallel.py
+@@ -22,43 +22,58 @@
+ #
+ ################################################################################
+ 
+-import concurrent.futures
+-import itertools
++import multiprocessing
+ import os
++import re
+ import sys
+ import time
+-
+-from joblib import Parallel, delayed
++from functools import partial
++from typing import Any, Callable
+ 
+ from .Utilities import tqdm
+ 
+ 
+-def joblibParallelSupportsGenerator():
+-    import joblib
+-    from packaging.version import Version
++def get_inherited_job_limit() -> int:
++    # 1. Check CMAKE_BUILD_PARALLEL_LEVEL (CMake 3.12+)
++    if 'CMAKE_BUILD_PARALLEL_LEVEL' in os.environ:
++        try:
++            return int(os.environ['CMAKE_BUILD_PARALLEL_LEVEL'])
++        except ValueError:
++            pass
+ 
+-    joblibVer = joblib.__version__
+-    return Version(joblibVer) >= Version("1.4.0")
++    # 2. Parse MAKEFLAGS for -jN
++    makeflags = os.environ.get('MAKEFLAGS', '')
++    match = re.search(r'-j\s*(\d+)', makeflags)
++    if match:
++        return int(match.group(1))
+ 
++    return -1
+ 
+-def CPUThreadCount(enable=True):
+-    from .GlobalParameters import globalParameters
+ 
++def CPUThreadCount(enable=True):
+     if not enable:
+         return 1
+-    else:
++    from .GlobalParameters import globalParameters
++
++    # Priority order:
++    # 1. Inherited from build system (CMAKE_BUILD_PARALLEL_LEVEL or MAKEFLAGS)
++    # 2. Explicit --jobs flag
++    # 3. Auto-detect
++    inherited_limit = get_inherited_job_limit()
++    cpuThreads = inherited_limit if inherited_limit > 0 else globalParameters["CpuThreads"]
++
++    if cpuThreads < 1:
+         if os.name == "nt":
+-            # Windows supports at most 61 workers because the scheduler uses
+-            # WaitForMultipleObjects directly, which has the limit (the limit
+-            # is actually 64, but some handles are needed for accounting).
+-            cpu_count = min(os.cpu_count(), 61)
++            cpuThreads = os.cpu_count()
+         else:
+-            cpu_count = len(os.sched_getaffinity(0))
+-        cpuThreads = globalParameters["CpuThreads"]
+-        if cpuThreads == -1:
+-            return cpu_count
++            cpuThreads = len(os.sched_getaffinity(0))
+ 
+-        return min(cpu_count, cpuThreads)
++    if os.name == "nt":
++        # Windows supports at most 61 workers because the scheduler uses
++        # WaitForMultipleObjects directly, which has the limit (the limit
++        # is actually 64, but some handles are needed for accounting).
++        cpuThreads = min(cpuThreads, 61)
++    return max(1, cpuThreads)
+ 
+ 
+ def pcallWithGlobalParamsMultiArg(f, args, newGlobalParameters):
+@@ -71,19 +86,22 @@ def pcallWithGlobalParamsSingleArg(f, arg, newGlobalParameters):
+     return f(arg)
+ 
+ 
+-def apply_print_exception(item, *args):
+-    # print(item, args)
++def OverwriteGlobalParameters(newGlobalParameters):
++    from . import GlobalParameters
++
++    GlobalParameters.globalParameters.clear()
++    GlobalParameters.globalParameters.update(newGlobalParameters)
++
++
++def worker_function(args, function, multiArg):
++    """Worker function that executes in the pool process."""
+     try:
+-        if len(args) > 0:
+-            func = item
+-            args = args[0]
+-            return func(*args)
++        if multiArg:
++            return function(*args)
+         else:
+-            func, item = item
+-            return func(item)
++            return function(args)
+     except Exception:
+         import traceback
+-
+         traceback.print_exc()
+         raise
+     finally:
+@@ -98,154 +116,116 @@ def OverwriteGlobalParameters(newGlobalParameters):
+     GlobalParameters.globalParameters.update(newGlobalParameters)
+ 
+ 
+-def ProcessingPool(enable=True, maxTasksPerChild=None):
+-    import multiprocessing
+-    import multiprocessing.dummy
+-
+-    threadCount = CPUThreadCount()
+-
+-    if (not enable) or threadCount <= 1:
+-        return multiprocessing.dummy.Pool(1)
+-
+-    if multiprocessing.get_start_method() == "spawn":
+-        from . import GlobalParameters
+-
+-        return multiprocessing.Pool(
+-            threadCount,
+-            initializer=OverwriteGlobalParameters,
+-            maxtasksperchild=maxTasksPerChild,
+-            initargs=(GlobalParameters.globalParameters,),
+-        )
+-    else:
+-        return multiprocessing.Pool(threadCount, maxtasksperchild=maxTasksPerChild)
++def progress_logger(iterable, total, message, min_log_interval=5.0):
++    """
++    Generator that wraps an iterable and logs progress with time-based throttling.
+ 
++    Only logs progress if at least min_log_interval seconds have passed since last log.
++    Only prints completion message if task took >= min_log_interval seconds.
+ 
+-def ParallelMap(function, objects, message="", enable=True, method=None, maxTasksPerChild=None):
+-    """
+-    Generally equivalent to list(map(function, objects)), possibly executing in parallel.
+-
+-      message: A message describing the operation to be performed.
+-      enable: May be set to false to disable parallelism.
+-      method: A function which can fetch the mapping function from a processing pool object.
+-          Leave blank to use .map(), other possiblities:
+-             - `lambda x: x.starmap` - useful if `function` takes multiple parameters.
+-             - `lambda x: x.imap` - lazy evaluation
+-             - `lambda x: x.imap_unordered` - lazy evaluation, does not preserve order of return value.
++    Yields (index, item) tuples.
+     """
+-    from .GlobalParameters import globalParameters
++    start_time = time.time()
++    last_log_time = start_time
++    log_interval = 1 + (total // 100)
+ 
+-    threadCount = CPUThreadCount(enable)
+-    pool = ProcessingPool(enable, maxTasksPerChild)
+-
+-    if threadCount <= 1 and globalParameters["ShowProgressBar"]:
+-        # Provide a progress bar for single-threaded operation.
+-        # This works for method=None, and for starmap.
+-        mapFunc = map
+-        if method is not None:
+-            # itertools provides starmap which can fill in for pool.starmap.  It provides imap on Python 2.7.
+-            # If this works, we will use it, otherwise we will fallback to the "dummy" pool for single threaded
+-            # operation.
+-            try:
+-                mapFunc = method(itertools)
+-            except NameError:
+-                mapFunc = None
+-
+-        if mapFunc is not None:
+-            return list(mapFunc(function, tqdm(objects, message)))
+-
+-    mapFunc = pool.map
+-    if method:
+-        mapFunc = method(pool)
+-
+-    objects = zip(itertools.repeat(function), objects)
+-    function = apply_print_exception
+-
+-    countMessage = ""
+-    try:
+-        countMessage = " for {} tasks".format(len(objects))
+-    except TypeError:
+-        pass
++    for idx, item in enumerate(iterable):
++        if idx % log_interval == 0:
++            current_time = time.time()
++            if (current_time - last_log_time) >= min_log_interval:
++                print(f"{message}\t{idx+1: 5d}/{total: 5d}")
++                last_log_time = current_time
++        yield idx, item
+ 
+-    if message != "":
+-        message += ": "
++    elapsed = time.time() - start_time
++    final_idx = idx + 1 if 'idx' in locals() else 0
+ 
+-    print("{0}Launching {1} threads{2}...".format(message, threadCount, countMessage))
+-    sys.stdout.flush()
+-    currentTime = time.time()
+-    rv = mapFunc(function, objects)
+-    totalTime = time.time() - currentTime
+-    print("{0}Done. ({1:.1f} secs elapsed)".format(message, totalTime))
+-    sys.stdout.flush()
+-    pool.close()
+-    return rv
++    if elapsed >= min_log_interval or last_log_time > start_time:
++        print(f"{message} done in {elapsed:.1f}s!\t{final_idx: 5d}/{total: 5d}")
+ 
+ 
+-def ParallelMapReturnAsGenerator(function, objects, message="", enable=True, multiArg=True):
+-    from .GlobalParameters import globalParameters
++def imap_with_progress(pool, func, iterable, total, message, chunksize):
++    results = []
++    for _, result in progress_logger(pool.imap(func, iterable, chunksize=chunksize), total, message):
++        results.append(result)
++    return results
+ 
+-    threadCount = CPUThreadCount(enable)
+-    print("{0}Launching {1} threads...".format(message, threadCount))
+ 
+-    if threadCount <= 1 and globalParameters["ShowProgressBar"]:
+-        # Provide a progress bar for single-threaded operation.
+-        callFunc = lambda args: function(*args) if multiArg else lambda args: function(args)
+-        return [callFunc(args) for args in tqdm(objects, message)]
++def _ParallelMap_generator(worker, objects, objLen, message, chunksize, threadCount, globalParameters):
++    # separate fn because yield makes the entire fn a generator even if unreachable
++    ctx = multiprocessing.get_context('forkserver' if os.name != 'nt' else 'spawn')
+ 
+-    with concurrent.futures.ProcessPoolExecutor(max_workers=threadCount) as executor:
+-        resultFutures = (executor.submit(function, *arg if multiArg else arg) for arg in objects)
+-        for result in concurrent.futures.as_completed(resultFutures):
+-            yield result.result()
++    with ctx.Pool(processes=threadCount, maxtasksperchild=1024,
++                  initializer=OverwriteGlobalParameters, initargs=(globalParameters,)) as pool:
++        for _, result in progress_logger(pool.imap_unordered(worker, objects, chunksize=chunksize), objLen, message):
++            yield result
+ 
+ 
+ def ParallelMap2(
+-    function, objects, message="", enable=True, multiArg=True, return_as="list", procs=None
++    function: Callable,
++    objects: Any,
++    message: str = "",
++    enable: bool = True,
++    multiArg: bool = True,
++    minChunkSize: int = 1,
++    return_as: str = "list"
+ ):
++    """Executes a function over a list of objects in parallel or sequentially.
++
++    This function is generally equivalent to ``list(map(function, objects))``. However, it provides
++    additional functionality to run in parallel, depending on the 'enable' flag and available CPU
++    threads.
++
++    Args:
++        function: The function to apply to each item in 'objects'. If 'multiArg' is True, 'function'
++                  should accept multiple arguments.
++        objects: An iterable of objects to be processed by 'function'. If 'multiArg' is True, each
++                 item in 'objects' should be an iterable of arguments for 'function'.
++        message: Optional; a message describing the operation. Default is an empty string.
++        enable: Optional; if False, disables parallel execution and runs sequentially. Default is True.
++        multiArg: Optional; if True, treats each item in 'objects' as multiple arguments for
++                  'function'. Default is True.
++        return_as: Optional; "list" (default) or "generator_unordered" for streaming results
++
++    Returns:
++        A list or generator containing the results of applying **function** to each item in **objects**.
+     """
+-    Generally equivalent to list(map(function, objects)), possibly executing in parallel.
++    from .GlobalParameters import globalParameters
+ 
+-      message: A message describing the operation to be performed.
+-      enable: May be set to false to disable parallelism.
+-      multiArg: True if objects represent multiple arguments
+-                  (differentiates multi args vs single collection arg)
+-    """
+-    if return_as in ("generator", "generator_unordered") and not joblibParallelSupportsGenerator():
+-        return ParallelMapReturnAsGenerator(function, objects, message, enable, multiArg)
++    threadCount = CPUThreadCount(enable)
+ 
+-    from .GlobalParameters import globalParameters
++    if not hasattr(objects, "__len__"):
++        objects = list(objects)
+ 
+-    threadCount = procs if procs else CPUThreadCount(enable)
++    objLen = len(objects)
++    if objLen == 0:
++        return [] if return_as == "list" else iter([])
+ 
+-    threadCount = CPUThreadCount(enable)
++    f = (lambda x: function(*x)) if multiArg else function
++    if objLen == 1:
++        print(f"{message}: (1 task)")
++        result = [f(x) for x in objects]
++        return result if return_as == "list" else iter(result)
+ 
+-    if threadCount <= 1 and globalParameters["ShowProgressBar"]:
+-        # Provide a progress bar for single-threaded operation.
+-        return [function(*args) if multiArg else function(args) for args in tqdm(objects, message)]
++    extra_message = (
++        f": {threadCount} thread(s)" + f", {objLen} tasks"
++        if objLen
++        else ""
++    )
+ 
+-    countMessage = ""
+-    try:
+-        countMessage = " for {} tasks".format(len(objects))
+-    except TypeError:
+-        pass
+-
+-    if message != "":
+-        message += ": "
+-    print("{0}Launching {1} threads{2}...".format(message, threadCount, countMessage))
+-    sys.stdout.flush()
+-    currentTime = time.time()
+-
+-    pcall = pcallWithGlobalParamsMultiArg if multiArg else pcallWithGlobalParamsSingleArg
+-    pargs = zip(objects, itertools.repeat(globalParameters))
+-
+-    if joblibParallelSupportsGenerator():
+-        rv = Parallel(n_jobs=threadCount, timeout=99999, return_as=return_as)(
+-            delayed(pcall)(function, a, params) for a, params in pargs
+-        )
++    print(f"ParallelMap {message}{extra_message}")
++
++    if threadCount <= 1:
++        result = [f(x) for x in objects]
++        return result if return_as == "list" else iter(result)
++
++    chunksize = max(minChunkSize, objLen // 2000)
++    worker = partial(worker_function, function=function, multiArg=multiArg)
++    if return_as == "generator_unordered":
++        # yield results as they complete without buffering
++        return _ParallelMap_generator(worker, objects, objLen, message, chunksize, threadCount, globalParameters)
+     else:
+-        rv = Parallel(n_jobs=threadCount, timeout=99999)(
+-            delayed(pcall)(function, a, params) for a, params in pargs
+-        )
+-
+-    totalTime = time.time() - currentTime
+-    print("{0}Done. ({1:.1f} secs elapsed)".format(message, totalTime))
+-    sys.stdout.flush()
+-    return rv
++        ctx = multiprocessing.get_context('forkserver' if os.name != 'nt' else 'spawn')
++        with ctx.Pool(processes=threadCount, maxtasksperchild=1024,
++                      initializer=OverwriteGlobalParameters, initargs=(globalParameters,)) as pool:
++            return list(imap_with_progress(pool, worker, objects, objLen, message, chunksize))
+diff --git a/tensilelite/Tensile/TensileCreateLibrary/Run.py b/tensilelite/Tensile/TensileCreateLibrary/Run.py
+index 835ed9c019..ad9fbf687c 100644
+--- a/tensilelite/Tensile/TensileCreateLibrary/Run.py
++++ b/tensilelite/Tensile/TensileCreateLibrary/Run.py
+@@ -26,6 +26,7 @@ import rocisa
+ 
+ import functools
+ import glob
++import gc
+ import itertools
+ import os
+ import shutil
+@@ -115,6 +116,29 @@ def processKernelSource(kernelWriterAssembly, data, splitGSU, kernel) -> KernelC
+     )
+ 
+ 
++def processAndAssembleKernelTCL(kernelWriterAssembly, rocisa_data, splitGSU, kernel, assemblyTmpPath, assembler):
++    """
++    Pipeline function for TCL mode that:
++    1. Generates kernel source
++    2. Writes .s file to disk
++    3. Assembles to .o file
++    4. Deletes .s file
++    """
++    result = processKernelSource(kernelWriterAssembly, rocisa_data, splitGSU, kernel)
++    return writeAndAssembleKernel(result, assemblyTmpPath, assembler)
++
++
++def writeMasterSolutionLibrary(name_lib_tuple, newLibraryDir, splitGSU, libraryFormat):
++    """
++    Write a master solution library to disk.
++    Module-level function to support multiprocessing.
++    """
++    name, lib = name_lib_tuple
++    filename = os.path.join(newLibraryDir, name)
++    lib.applyNaming(splitGSU)
++    LibraryIO.write(filename, state(lib), libraryFormat)
++
++
+ def removeInvalidSolutionsAndKernels(results, kernels, solutions, errorTolerant, printLevel: bool, splitGSU: bool):
+     removeKernels = []
+     removeKernelNames = []
+@@ -189,6 +213,24 @@ def writeAssembly(asmPath: Union[Path, str], result: KernelCodeGenResult):
+     return path, isa, wfsize, minResult
+ 
+ 
++def writeAndAssembleKernel(result: KernelCodeGenResult, asmPath: Union[Path, str], assembler):
++    """Write assembly file and immediately assemble it to .o file"""
++    if result.err:
++        printExit(f"Failed to build kernel {result.name} because it has error code {result.err}")
++
++    path = Path(asmPath) / f"{result.name}.s"
++    with open(path, "w", encoding="utf-8") as f:
++        f.write(result.src)
++
++    # Assemble .s -> .o
++    assembler(isaToGfx(result.isa), result.wavefrontSize, str(path), str(path.with_suffix(".o")))
++
++    # Delete assembly file immediately to save disk space
++    path.unlink()
++
++    return KernelMinResult(result.err, result.cuoccupancy, result.pgr, result.mathclk)
++
++
+ def writeHelpers(
+     outputPath, kernelHelperObjs, KERNEL_HELPER_FILENAME_CPP, KERNEL_HELPER_FILENAME_H
+ ):
+@@ -268,13 +310,14 @@ def writeSolutionsAndKernels(
+     numAsmKernels = len(asmKernels)
+     numKernels = len(asmKernels)
+     assert numKernels == numAsmKernels, "Only assembly kernels are supported in TensileLite"
+-    asmIter = zip(
+-        itertools.repeat(kernelWriterAssembly),
+-        itertools.repeat(rocisa.rocIsa.getInstance().getData()),
+-        itertools.repeat(splitGSU),
+-        asmKernels
++
++    processKernelFn = functools.partial(
++        processKernelSource,
++        kernelWriterAssembly=kernelWriterAssembly,
++        data=rocisa.rocIsa.getInstance().getData(),
++        splitGSU=splitGSU
+     )
+-    asmResults = ParallelMap2(processKernelSource, asmIter, "Generating assembly kernels", return_as="list")
++    asmResults = ParallelMap2(processKernelFn, asmKernels, "Generating assembly kernels", return_as="list", multiArg=False)
+     removeInvalidSolutionsAndKernels(
+         asmResults, asmKernels, solutions, errorTolerant, getVerbosity(), splitGSU
+     )
+@@ -282,14 +325,14 @@ def writeSolutionsAndKernels(
+         asmResults, asmKernels, solutions, splitGSU
+     )
+ 
+-    def assemble(ret):
+-        p, isa, wavefrontsize, result = ret
+-        asmToolchain.assembler(isaToGfx(isa), wavefrontsize, str(p), str(p.with_suffix(".o")))
+-
+-    unaryWriteAssembly = functools.partial(writeAssembly, assemblyTmpPath)
+-    compose = lambda *F: functools.reduce(lambda f, g: lambda x: f(g(x)), F)
++    # Use functools.partial to bind assemblyTmpPath and assembler
++    writeAndAssembleFn = functools.partial(
++        writeAndAssembleKernel,
++        asmPath=assemblyTmpPath,
++        assembler=asmToolchain.assembler
++    )
+     ret = ParallelMap2(
+-        compose(assemble, unaryWriteAssembly),
++        writeAndAssembleFn,
+         asmResults,
+         "Writing assembly kernels",
+         return_as="list",
+@@ -369,32 +412,31 @@ def writeSolutionsAndKernelsTCL(
+ 
+     uniqueAsmKernels = [k for k in asmKernels if not k.duplicate]
+ 
+-    def assemble(ret):
+-        p, isa, wavefrontsize, result = ret
+-        asmToolchain.assembler(isaToGfx(isa), wavefrontsize, str(p), str(p.with_suffix(".o")))
+-        return result
+-
+-    unaryProcessKernelSource = functools.partial(
+-        processKernelSource,
++    processKernelFn = functools.partial(
++        processAndAssembleKernelTCL,
+         kernelWriterAssembly,
+         rocisa.rocIsa.getInstance().getData(),
+         splitGSU,
++        assemblyTmpPath=assemblyTmpPath,
++        assembler=asmToolchain.assembler
+     )
+ 
+-    unaryWriteAssembly = functools.partial(writeAssembly, assemblyTmpPath)
+-    compose = lambda *F: functools.reduce(lambda f, g: lambda x: f(g(x)), F)
+-    ret = ParallelMap2(
+-        compose(assemble, unaryWriteAssembly, unaryProcessKernelSource),
++    results = ParallelMap2(
++        processKernelFn,
+         uniqueAsmKernels,
+         "Generating assembly kernels",
+         multiArg=False,
+         return_as="list"
+     )
++    del processKernelFn
++    gc.collect()
++
+     passPostKernelInfoToSolution(
+-        ret, uniqueAsmKernels, solutions, splitGSU
++        results, uniqueAsmKernels, solutions, splitGSU
+     )
+-    # result.src is very large so let garbage collector know to clean up
+-    del ret
++    del results
++    gc.collect()
++
+     buildAssemblyCodeObjectFiles(
+         asmToolchain.linker,
+         asmToolchain.bundler,
+@@ -508,16 +550,6 @@ def generateLogicDataAndSolutions(logicFiles, args, assembler: Assembler, isaInf
+     printSolutionRejectionReason = True
+     printIndexAssignmentInfo = False
+ 
+-    fIter = zip(
+-        logicFiles,
+-        itertools.repeat(assembler),
+-        itertools.repeat(splitGSU),
+-        itertools.repeat(printSolutionRejectionReason),
+-        itertools.repeat(printIndexAssignmentInfo),
+-        itertools.repeat(isaInfoMap),
+-        itertools.repeat(args["LazyLibraryLoading"]),
+-    )
+-
+     def libraryIter(lib: MasterSolutionLibrary):
+         if len(lib.solutions):
+             for i, s in enumerate(lib.solutions.items()):
+@@ -526,8 +558,19 @@ def generateLogicDataAndSolutions(logicFiles, args, assembler: Assembler, isaInf
+             for _, lazyLib in lib.lazyLibraries.items():
+                 yield from libraryIter(lazyLib)
+ 
++    parseLogicFn = functools.partial(
++        LibraryIO.parseLibraryLogicFile,
++        assembler=assembler,
++        splitGSU=splitGSU,
++        printSolutionRejectionReason=printSolutionRejectionReason,
++        printIndexAssignmentInfo=printIndexAssignmentInfo,
++        isaInfoMap=isaInfoMap,
++        lazyLibraryLoading=args["LazyLibraryLoading"]
++    )
++
+     for library in ParallelMap2(
+-        LibraryIO.parseLibraryLogicFile, fIter, "Loading Logics...", return_as="generator_unordered"
++        parseLogicFn, logicFiles, "Loading Logics...",
++        return_as="generator_unordered", minChunkSize=32, multiArg=False,
+     ):
+         _, architectureName, _, _, _, newLibrary = library
+ 
+@@ -751,11 +794,6 @@ def run():
+             if kName not in solDict:
+                 solDict["%s"%kName] = kernel
+ 
+-    def writeMsl(name, lib):
+-        filename = os.path.join(newLibraryDir, name)
+-        lib.applyNaming(splitGSU)
+-        LibraryIO.write(filename, state(lib), arguments["LibraryFormat"])
+-
+     filename = os.path.join(newLibraryDir, "TensileLiteLibrary_lazy_Mapping")
+     LibraryIO.write(filename, libraryMapping, "msgpack")
+ 
+@@ -774,9 +812,17 @@ def run():
+                     kName = getKeyNoInternalArgs(s.originalSolution, splitGSU)
+                     s.sizeMapping.CUOccupancy = solDict["%s"%kName]["CUOccupancy"]
+ 
+-            ParallelMap2(writeMsl,
++            writeFn = functools.partial(
++                writeMasterSolutionLibrary,
++                newLibraryDir=newLibraryDir,
++                splitGSU=splitGSU,
++                libraryFormat=arguments["LibraryFormat"]
++            )
++
++            ParallelMap2(writeFn,
+                          newMasterLibrary.lazyLibraries.items(),
+                          "Writing master solution libraries",
++                         multiArg=False,
+                          return_as="list")
+     stop_msl = timer()
+     print(f"Time to write master solution libraries (s): {(stop_msl-start_msl):3.2f}")
+diff --git a/tensilelite/Tensile/TensileMergeLibrary.py b/tensilelite/Tensile/TensileMergeLibrary.py
+index e33c617b6f..ba163e9918 100644
+--- a/tensilelite/Tensile/TensileMergeLibrary.py
++++ b/tensilelite/Tensile/TensileMergeLibrary.py
+@@ -303,8 +303,7 @@ def avoidRegressions(originalDir, incrementalDir, outputPath, forceMerge, noEff=
+         logicsFiles[origFile] = origFile
+         logicsFiles[incFile] = incFile
+ 
+-    iters = zip(logicsFiles.keys())
+-    logicsList = ParallelMap2(loadData, iters, "Loading Logics...", return_as="list")
++    logicsList = ParallelMap2(loadData, logicsFiles.keys(), "Loading Logics...", return_as="list", multiArg=False)
+     logicsDict = {}
+     for i, _ in enumerate(logicsList):
+         logicsDict[logicsList[i][0]] = logicsList[i][1]
+diff --git a/tensilelite/Tensile/TensileUpdateLibrary.py b/tensilelite/Tensile/TensileUpdateLibrary.py
+index 5ff265d0ed..c1803a6349 100644
+--- a/tensilelite/Tensile/TensileUpdateLibrary.py
++++ b/tensilelite/Tensile/TensileUpdateLibrary.py
+@@ -26,7 +26,7 @@ from . import LibraryIO
+ from .Tensile import addCommonArguments, argUpdatedGlobalParameters
+ 
+ from .Common import assignGlobalParameters, print1, restoreDefaultGlobalParameters, HR, \
+-                    globalParameters, architectureMap, ensurePath, ParallelMap, __version__
++                    globalParameters, architectureMap, ensurePath, ParallelMap2, __version__
+ 
+ import argparse
+ import copy
+@@ -149,7 +149,7 @@ def TensileUpdateLibrary(userArgs):
+     for logicFile in logicFiles:
+         print("#   %s" % logicFile)
+     fIter = zip(logicFiles, itertools.repeat(args.logic_path), itertools.repeat(outputPath))
+-    libraries = ParallelMap(UpdateLogic, fIter, "Updating logic files", method=lambda x: x.starmap)
++    libraries = ParallelMap2(UpdateLogic, fIter, "Updating logic files", multiArg=True, return_as="list")
+ 
+ 
+ def main():
+diff --git a/tensilelite/Tensile/Toolchain/Assembly.py b/tensilelite/Tensile/Toolchain/Assembly.py
+index a8b91e8d62..265e1d532c 100644
+--- a/tensilelite/Tensile/Toolchain/Assembly.py
++++ b/tensilelite/Tensile/Toolchain/Assembly.py
+@@ -30,7 +30,7 @@ import subprocess
+ from pathlib import Path
+ from typing import List, Union, NamedTuple
+ 
+-from Tensile.Common import print2
++from Tensile.Common import print1, print2
+ from Tensile.Common.Architectures import isaToGfx
+ from ..SolutionStructs import Solution
+ 
+@@ -92,8 +92,26 @@ def buildAssemblyCodeObjectFiles(
+         if coName:
+           coFileMap[asmDir / (coName + extCoRaw)].add(str(asmDir / (kernel["BaseName"] + extObj)))
+ 
++      # Build reference count map for .o files to handle shared object files
++      # (.o files from kernels marked .duplicate in TensileCreateLibrary)
++      objFileRefCount = collections.Counter()
++      for coFileRaw, objFiles in coFileMap.items():
++        for objFile in objFiles:
++          objFileRefCount[objFile] += 1
++
++      sharedObjFiles = {objFile: count for objFile, count in objFileRefCount.items() if count > 1}
++      if sharedObjFiles:
++        print1(f"Found {len(sharedObjFiles)} .o files shared across multiple code objects:")
++
+       for coFileRaw, objFiles in coFileMap.items():
+         linker(objFiles, str(coFileRaw))
++
++        # Delete .o files after linking once usage count reaches 0
++        for objFile in objFiles:
++          objFileRefCount[objFile] -= 1
++          if objFileRefCount[objFile] == 0:
++            Path(objFile).unlink()
++
+         coFile = destDir / coFileRaw.name.replace(extCoRaw, extCo)
+         if compress:
+           bundler.compress(str(coFileRaw), str(coFile), gfx)
+diff --git a/tensilelite/requirements.txt b/tensilelite/requirements.txt
+index 60c4c11445..5c8fd66a88 100644
+--- a/tensilelite/requirements.txt
++++ b/tensilelite/requirements.txt
+@@ -2,8 +2,6 @@ dataclasses; python_version == '3.6'
+ packaging
+ pyyaml
+ msgpack
+-joblib>=1.4.0; python_version >= '3.8'
+-joblib>=1.1.1; python_version < '3.8'
+ simplejson
+ ujson
+ orjson
diff --git a/pkgs/development/rocm-modules/6/hipblaslt/default.nix b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
index e8061a50b92f72..9883da5424bc91 100644
--- a/pkgs/development/rocm-modules/6/hipblaslt/default.nix
+++ b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
@@ -54,7 +54,6 @@ let
     ps.setuptools
     ps.packaging
     ps.nanobind
-    ps.joblib
     ps.msgpack
   ]);
   # workaround: build for one working target if no targets are supported
@@ -114,6 +113,9 @@ stdenv.mkDerivation (finalAttrs: {
     # excessive comments are written to temporary asm files in build dir
     # TODO: report upstream, find a better solution
     ./reduce-comment-spam.patch
+    # [hipblaslt] Refactor Parallel.py to drop joblib, massively reduce peak disk space usage
+    # https://github.com/ROCm/rocm-libraries/pull/2073
+    ./TensileCreateLibrary-refactor.patch
   ];
 
   postPatch = ''
@@ -155,7 +157,6 @@ stdenv.mkDerivation (finalAttrs: {
     msgpack-cxx
     libxml2
     python3Packages.msgpack
-    python3Packages.joblib
     zlib
     zstd
   ]

From a436d1c55be6457f53db4653bb7c5e390807450a Mon Sep 17 00:00:00 2001
From: Luna Nova <git@lunnova.dev>
Date: Sat, 11 Oct 2025 18:07:26 -0700
Subject: [PATCH 4/4] rocmPackages.hipblaslt: remove comment patch

no longer needed now we unlink .s / .o files as soon as possible
---
 .../rocm-modules/6/hipblaslt/default.nix      |  3 --
 .../6/hipblaslt/reduce-comment-spam.patch     | 47 -------------------
 2 files changed, 50 deletions(-)
 delete mode 100644 pkgs/development/rocm-modules/6/hipblaslt/reduce-comment-spam.patch

diff --git a/pkgs/development/rocm-modules/6/hipblaslt/default.nix b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
index 9883da5424bc91..a85f22c19b5004 100644
--- a/pkgs/development/rocm-modules/6/hipblaslt/default.nix
+++ b/pkgs/development/rocm-modules/6/hipblaslt/default.nix
@@ -110,9 +110,6 @@ stdenv.mkDerivation (finalAttrs: {
     # Support loading zstd compressed .dat files, required to keep output under
     # hydra size limit
     ./messagepack-compression-support.patch
-    # excessive comments are written to temporary asm files in build dir
-    # TODO: report upstream, find a better solution
-    ./reduce-comment-spam.patch
     # [hipblaslt] Refactor Parallel.py to drop joblib, massively reduce peak disk space usage
     # https://github.com/ROCm/rocm-libraries/pull/2073
     ./TensileCreateLibrary-refactor.patch
diff --git a/pkgs/development/rocm-modules/6/hipblaslt/reduce-comment-spam.patch b/pkgs/development/rocm-modules/6/hipblaslt/reduce-comment-spam.patch
deleted file mode 100644
index 32969c51778102..00000000000000
--- a/pkgs/development/rocm-modules/6/hipblaslt/reduce-comment-spam.patch
+++ /dev/null
@@ -1,47 +0,0 @@
-diff --git a/projects/hipblaslt/tensilelite/rocisa/rocisa/include/format.hpp b/projects/hipblaslt/tensilelite/rocisa/rocisa/include/format.hpp
-index b7dcb6f59a..b0625ba769 100644
---- a/tensilelite/rocisa/rocisa/include/format.hpp
-+++ b/tensilelite/rocisa/rocisa/include/format.hpp
-@@ -8,11 +8,13 @@ namespace rocisa
-     // Text format functions
-     inline std::string slash(const std::string& comment)
-     {
-+        return "";
-         return "// " + comment + "\n";
-     }
- 
-     inline std::string slash50(const std::string& comment)
-     {
-+        return "";
-         std::ostringstream oss;
-         oss << std::setw(50) << ""
-             << " // " << comment << "\n";
-@@ -21,16 +23,19 @@ namespace rocisa
- 
-     inline std::string block(const std::string& comment)
-     {
-+        return "";
-         return "/* " + comment + " */\n";
-     }
- 
-     inline std::string blockNewLine(const std::string& comment)
-     {
-+        return "";
-         return "\n/* " + comment + " */\n";
-     }
- 
-     inline std::string block3Line(const std::string& comment)
-     {
-+        return "";
-         std::ostringstream oss;
-         oss << "\n/******************************************/\n";
-         std::istringstream iss(comment);
-@@ -52,7 +57,7 @@ namespace rocisa
-         {
-             formattedStr = "\"" + formattedStr + "\\n\\t\"";
-         }
--        if(!comment.empty())
-+        if(false)
-         {
-             std::string buffer = formattedStr
-                                  + std::string(std::max(0, 50 - int(formattedStr.length())), ' ')
